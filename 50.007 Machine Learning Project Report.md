# 50.007 Machine Learning Project Report

*Seah Qi Yan 1004628* | *Ong Kah Yuan Joel 1004366*

[toc]

## Part 1: Labelling

Omitted.

## Part 2: Emission

The first order of business is to use maximum likelihood estimation to estimate the emission parameters from the training set, as per the equation below:
$$
e(x|y) = \frac{Count(y\rightarrow x)}{Count(y)}
$$
Our implementation of this can be found in the private method `__est_emission_params()` in the class part2. Here, we use a dictionary `count_y`, `count_y_to_x`, and `e_x_given_y` to keep track of the total number of occurrences of y, total number of emissions from y to x, and the probability of an emission of an x for a given y. We first populate `count_y_to_x` by iterating through the dataset, then iterating through that to populate `count_y`. Finally, `e_x_given_y` is generated as follows:

```python
#If the word token x:
for entry, count in count_y_to_x.items(): #where entry is a tuple (x,y)
	self.e_x_given_y[entry] = count/count_y[entry[1]]
    
#If the word token x is the special token #UNK#:
for entry, count in count_y.items(): #where entry is y
	self.e_x_given_y[("#UNK#",entry)] = 0.5/(count+0.5)

```

There is also the need to produce the tag:
$$
y^* = \underset{y}{\textrm{arg max }}e(x|y)
$$
for each word x in the sequence. This is done in the method `find_y_max_given_x`, which simply iterates through `e_x_given_y`, getting the value x that is associated with the highest probability for a given y, and associating the respective x and y as a key-value pair in the dictionary `x_max_prob`. Specifically, the code does the following:

```python
for entry, prob in self.e_x_given_y.items(): #where entry is a tuple (x,y)
    if entry[0] not in x_max_prob:
        x_max_prob[entry[0]] = prob
        self.y_max_given_x[entry[0]] = entry[1]
     else:
        if x_max_prob[entry[0]]<prob:
            x_max_prob[entry[0]] = prob
            self.y_max_given_x[entry[0]] = entry[1]
```

## Part 3: Transmission and Viterbi

We first need to estimate the transition parameters from the training set according to the following equation:
$$
q(y_i|y_{i-1})=\frac{Count(y_{i-1},y_i)}{Count(y_{i-1})}
$$
Our implementation (`est_transition_params` in the part3 class) uses...

We then need to use the Viterbi algorithm to compute the following:
$$
y_1^*,...,y_n^*=\underset{y_1,...,y_n}{\textrm{arg max }}p(x_1,...,x_n,y_1,...,y_n)
$$
In particular, we use the dynamic programming sequence:
$$
\pi(j+1,u) = \textrm{max}_v\{\pi(j,v)\times b_u(x_{j+1})\times a_{v,u}\} \\
\textrm{where: }\\
\begin{align}
\pi &= \textrm{a 2-D array}\\
u &= \textrm{current node}\\
v &= \textrm{previous node}\\
a &= \textrm{transition probability}\\
b &= \textrm{emission probarbility}
\end{align}
$$


## Part 4: Top 3 Sequences



## Part 5: Design Challenge

